# Sample config file
# The values mentioned are the default values

[logging]
# The directory to store the log files
directory = "log"
# The name of the current log file
active_file_name = "out.log"

# File will be rotated whenever any one of these conditions are met
[rotation]
# Max no. of lines beyond which the file will rotate
max_lines = 100000 # hundred thousand
# Max no. of bytes written to a file beyond which it will rotate
max_file_size_bytes = 5000000 # 5MB

# The time interval after which the buffer will be flushed to disk.
# This is only for file output. If other targets need a flush interval, you need to specify it separately. Look at the [target] section for examples.
[flushing]
time_interval_secs = 5

[rollup]
# Specify file rename policy.
# Values accepted are
# timestamp - rotated files will be named with the timestamp at the moment of rotation
# serial - rotated files will be named serially in an increasing sequence
file_rename_policy = "timestamp"
# The maximum age of a file beyond which it will be removed
# Suffix must be either d(days) or h(hours)
max_age = "30d"
# The maximum no. of files to keep in the log directory
# Older files will be deleted first
max_count = 100
# Whether to gzip the rolled over files or not
gzip = false

[misc]
# Populate the following variable if you want to
# prepend your log line with a predefined text.
# There are some template values you can use too.
# {{.Timestamp}} expands to a timestamp in RFC822 format
# {{.UnixTimestamp}} expands to a unix epoch timestamp to nanosecond precision
#
# Example -
# prepend_value = "[app_name]- "
# prepend_value = "[app_name] {{.Timestamp}}- "
prepend_value = ""

# Specifies the output target to send the logs to. Uncomment the output you want.
# You can omit this section if you are just logging to files.

# Kafka output example
# [target]
# name = "kafka"
# brokers = ["host1:port", "host2:port"]
# topic = "testtopic"
# clientID = "funnel"
# You need not set the below 2 settings. They will be set to kafka default values if not specified
# flush_frequency_secs = 5 # Best-effort frequency of flushing messages
# batch_size = 10 # Best-effort num of messages to trigger a flush

# ElasticSearch output example
# P.S. - Log lines have to be in json parsable format
# [target]
# name = "elasticsearch"
# nodes = ["http://host1:port", "http://host2:port"]
# index = "testindex"
# type = "testtype"

